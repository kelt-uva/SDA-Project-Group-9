{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDA Project | Team 9\n",
    "\n",
    "### Students:\n",
    "\n",
    "Fennom Schalkwijk - 14619148 \\\n",
    "Kelt Paehlig - 14634716\n",
    "\n",
    "For more info about the project, see the README.\n",
    "\n",
    "This notebook contains the code for the analysis of the dataset (week 2-4). The notebook is divided into\n",
    "sections, see the table of contents below.\n",
    "\n",
    "### Table of Contents:\n",
    "\n",
    "1. [Reformatting Data for Logistic Regression](#reformatting-data)  \n",
    "   1.1 [Categorial data to numerical data](#categorial-to-numerical)  \n",
    "   1.2 [Multiple categories](#multiple-categories)  \n",
    "   1.3 [Normalisation of numerical values](#normalisation)  \n",
    "   1.4 [Dropping consumption columns](#dropping-consumption)  \n",
    "   1.5 [Correlation matrix](#correlation-matrix)  \n",
    "   1.6 [Plots of healthy people against people with heart disease](#plots-healthy-unhealthy)\n",
    "2. [Running a basic logistic regression model](#logistic-regression)  \n",
    "   2.1 [Creating training and testing data](#testing-training-data)  \n",
    "   2.2 [Running model](#running-model)  \n",
    "   2.3 [Simulating coefficients](#simulating-coefficients)\n",
    "3. [Principal Component Analysis](#pca)  \n",
    "   3.1 [Finding amount of components needed](#amount-components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necesarry imports, add any new ones here and update `requirements.txt` by running `pip freeze > requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add folder for graphs of results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"../Graphs/results/\", \"../Graphs/dataset/\"]\n",
    "\n",
    "for path in paths:\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print(\"Making path {path} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Data/CVD_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting the data for logistic regression\n",
    "\n",
    "<a id='reformatting-data'></a>\n",
    "\n",
    "### Categorial data to numerical data\n",
    "\n",
    "<a id='categorial-to-numerical'></a>\n",
    "\n",
    "Before we are able to do any sort of analysis on the dataset, we need to ensure that the data has a format that we are able to do 'math' with. As an example, 'yes' or 'no' is not something we can do math with, so we have to convert this properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat every yes and no to a binary 0 or 1. For sex, we will take male to be 1 and female to be 0. We also change the name to 'Sex_Male' to make this more clear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data.replace(\n",
    "        {\n",
    "            \"Skin_Cancer\": \"Yes\",\n",
    "            \"Other_Cancer\": \"Yes\",\n",
    "            \"Heart_Disease\": \"Yes\",\n",
    "            \"Depression\": \"Yes\",\n",
    "            \"Smoking_History\": \"Yes\",\n",
    "            \"Exercise\": \"Yes\",\n",
    "            \"Sex\": \"Male\",\n",
    "            \"Arthritis\": \"Yes\",\n",
    "        },\n",
    "        1,\n",
    "    )\n",
    "    .replace(\n",
    "        {\n",
    "            \"Skin_Cancer\": \"No\",\n",
    "            \"Other_Cancer\": \"No\",\n",
    "            \"Heart_Disease\": \"No\",\n",
    "            \"Depression\": \"No\",\n",
    "            \"Smoking_History\": \"No\",\n",
    "            \"Exercise\": \"No\",\n",
    "            \"Sex\": \"Female\",\n",
    "            \"Arthritis\": \"No\",\n",
    "        },\n",
    "        0,\n",
    "    )\n",
    "    .rename(columns={\"Sex\": \"Sex_Male\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data which first was 'yes' or 'no' now has a binary value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple categories <a id='multiple-categories'></a>\n",
    "\n",
    "There are a few columns which work with categries, such as age ranges or yes/no or \"yes, ...\". We will also have to somehow convert these into a format that we can work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Age_Category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Diabetes\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Checkup\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"General_Health\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the age range, we will take the value exactly in the middle of the range (average). For the 80+ range, we will take 85. For diabetes, we have grouped the different types of diabeted into one category, ending up with either yes or no. For the recent checkups, we split the group into the people that had a checkup in the last two years and the people that did not. The perceived health is split up into a group that says their health is good or better, and the group that says their health is fair or poor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set age to numerical by taking the mean of the existing categories (ASSUMPTION: 80+ is estimated to 85)\n",
    "age_mapping = {\n",
    "    \"18-24\": 21.0,\n",
    "    \"25-29\": 27.0,\n",
    "    \"30-34\": 32.0,\n",
    "    \"35-39\": 37.0,\n",
    "    \"40-44\": 42.0,\n",
    "    \"45-49\": 47.0,\n",
    "    \"50-54\": 52.0,\n",
    "    \"55-59\": 57.0,\n",
    "    \"60-64\": 62.0,\n",
    "    \"65-69\": 67.0,\n",
    "    \"70-74\": 72.0,\n",
    "    \"75-79\": 77.0,\n",
    "    \"80+\": 85.0,\n",
    "}\n",
    "\n",
    "data[\"Age_Category\"] = data[\"Age_Category\"].map(age_mapping)\n",
    "data = data.rename(columns={\"Age_Category\": \"Age_Numeric\"})\n",
    "\n",
    "# Normalize age (done in such a way that we can interpret an increase in age as a 10 year increase over the average age)\n",
    "data[\"Age_Numeric\"] = (data[\"Age_Numeric\"] - data[\"Age_Numeric\"].mean()) / 10\n",
    "data = data.rename(columns={\"Age_Numeric\": \"Age_Normalised\"})\n",
    "\n",
    "# Diabetes, we group everyone that every had diabetes as diabetic, and the\n",
    "# people who never had diabetes as non diabetic.\n",
    "diabetes_binary = [0 if i == \"No\" else 1 for i in data[\"Diabetes\"]]\n",
    "data[\"Diabetes\"] = diabetes_binary\n",
    "data = data.rename(columns={\"Diabetes\": \"Diabetic\"})\n",
    "\n",
    "# We split the checkup group into the people who has a checkup in the last two years\n",
    "# and the people who did not.\n",
    "checkup_binary = [\n",
    "    1 if i == \"Within the past year\" or i == \"Within the past 2 years\" else 0\n",
    "    for i in data[\"Checkup\"]\n",
    "]\n",
    "data[\"Checkup\"] = checkup_binary\n",
    "data = data.rename(columns={\"Checkup\": \"Recent_Checkup\"})\n",
    "\n",
    "# Perceived health is split into the group with good or better health\n",
    "# and the group with fair or poor health.\n",
    "health_binary = [0 if i == \"Fair\" or i == \"Poor\" else 1 for i in data[\"General_Health\"]]\n",
    "data[\"General_Health\"] = health_binary\n",
    "data = data.rename(columns={\"General_Health\": \"Health_Good_or_Better\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation of numerical values <a id='normalisation'></a>\n",
    "\n",
    "The numerical values in the dataset must be normalised in order to ensure we can focus on patterns and not on scale. We use the simple formula:\n",
    "$$y = \\frac{(x - min)}{(max - min)}$$\n",
    "\n",
    "This is done for all the numerical columns in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data: list[int | float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    This function takes a column of data and normalizes it.\n",
    "    This is done with the formula (x - min) / (max - min).\n",
    "    The entire column is returned as a list with every value\n",
    "    normalized.\n",
    "    \"\"\"\n",
    "    min_value = min(data)\n",
    "    max_value = max(data)\n",
    "    normalized_data = []\n",
    "\n",
    "    for value in data:\n",
    "        new_value = (value - min_value) / (max_value - min_value)\n",
    "        normalized_data.append(new_value)\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "# Normalise the height (done in such a way that we can interpret an increase in height as a 10 cm increase over the average height)\n",
    "data[\"Height_(cm)\"] = (data[\"Height_(cm)\"] - data[\"Height_(cm)\"].mean()) / 10\n",
    "data = data.rename(columns={\"Height_(cm)\": \"Height_norm\"})\n",
    "\n",
    "# Normalise the weight (done in such a way that we can interpret an increase in weight as a 5 kg increase over the average weight)\n",
    "data[\"Weight_(kg)\"] = (data[\"Weight_(kg)\"] - data[\"Weight_(kg)\"].mean()) / 5\n",
    "data = data.rename(columns={\"Weight_(kg)\": \"Weight_norm\"})\n",
    "\n",
    "# Normalise the bmi (done in such a way that we can interpret an increase in bmi as a 1 point increase over the average bmi)\n",
    "data[\"BMI\"] = data[\"BMI\"] - data[\"BMI\"].mean()\n",
    "data = data.rename(columns={\"BMI\": \"BMI_norm\"})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping consumption columns <a id='dropping-consumption'></a>\n",
    "\n",
    "The author of the dataset has no information on the columns Alcohol_Consumption, Fruit_Consumption, Green_Vegetables_Consumption, FriedPotato_Consumption. From the survey it is possible that these columns are the frequency that someone consumes these items in a month but we can not be sure. Because of this, we are going to drop these columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\n",
    "    columns=[\n",
    "        \"Alcohol_Consumption\",\n",
    "        \"Fruit_Consumption\",\n",
    "        \"Green_Vegetables_Consumption\",\n",
    "        \"FriedPotato_Consumption\",\n",
    "    ]\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix\n",
    "\n",
    "<a id='correlation-matrix'></a>\n",
    "\n",
    "Now that all the data is in a format that can be worked with, we can make a correlation matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(\n",
    "    corr, annot=True, cmap=\"coolwarm\"\n",
    ")  # We use sns to easily get the actual values of each correlation in the figure\n",
    "plt.savefig(\"../Graphs/dataset/correlation_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shows us some interesting relations. At first, we can see that weight and height are correlated, which makes sense. BMI and weight are correlated, which also makes sense. We can see that people that report having some medical condition, such as arthritis, diabetes or even heart disease correlate to having a worse perceived health. It is surprising that recent checkups do not correlate much with heart disease. The frequency of the checkups does not say much about the health of the person. From the correlation matrix alone it is hard to say much about finding any predictors for heart disease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of healthy people against people with heart disease <a id='plots-healthy-unhealthy'></a>\n",
    "\n",
    "We will plot the histograms and inspect whether there is a big difference between the data for healthy people and people with heart disease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_heart_disease = data.loc[data[\"Heart_Disease\"] == 0]\n",
    "heart_disease = data.loc[data[\"Heart_Disease\"] == 1]\n",
    "\n",
    "no_heart_disease_y = no_heart_disease[\"Heart_Disease\"]  # y vector\n",
    "heart_disease_y = heart_disease[\"Heart_Disease\"]  # y vector\n",
    "\n",
    "no_heart_disease = no_heart_disease.drop(columns=[\"Heart_Disease\"])\n",
    "heart_disease = heart_disease.drop(columns=[\"Heart_Disease\"])\n",
    "\n",
    "fig, axs = plt.subplots(5, 3, figsize=(25, 30))\n",
    "\n",
    "c = 0\n",
    "for i in range(14):\n",
    "    plt.subplot(5, 3, i + 1)\n",
    "    plt.hist(\n",
    "        no_heart_disease[no_heart_disease.columns[i]],\n",
    "        label=\"No heart disease\",\n",
    "        alpha=0.5,\n",
    "        color=\"b\",\n",
    "    )\n",
    "    plt.hist(\n",
    "        heart_disease[heart_disease.columns[i]],\n",
    "        label=\"Heart disease\",\n",
    "        alpha=0.5,\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    plt.xlabel(no_heart_disease.columns[i])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\n",
    "        f\"Data of {no_heart_disease.columns[i]} for people with and without heart disease\"\n",
    "    )\n",
    "\n",
    "    unique_vals = no_heart_disease[no_heart_disease.columns[i]].unique()\n",
    "    if len(unique_vals) == 2 and all([x in [0, 1] for x in unique_vals]):\n",
    "        plt.xticks([0, 1], [\"No\", \"Yes\"])\n",
    "\n",
    "    plt.legend()\n",
    "    c += 1\n",
    "\n",
    "fig.delaxes(axs[-1, -1])  # remove the empty subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs do not immediately show a clear difference between the two groups, so we can not conclude much about this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a basic logistic regression model\n",
    "\n",
    "<a id='logistic-regression'></a>\n",
    "\n",
    "### Creating training and testing data\n",
    "\n",
    "<a id='testing-training-data'></a>\n",
    "\n",
    "We split the data into training and testing sets. We use 75% of the data for training and 25% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and Y and adding a constant\n",
    "Y = data[\"Heart_Disease\"]\n",
    "X = data.drop(columns=\"Heart_Disease\")\n",
    "X_intercept = sm.add_constant(X)\n",
    "\n",
    "# recombining XY\n",
    "column_names = [\"constant\"]\n",
    "for i in data.columns:\n",
    "    column_names.append(i)\n",
    "\n",
    "XY_constant = pd.DataFrame(\n",
    "    np.hstack((np.array(Y)[:, np.newaxis], X_intercept)), columns=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into test and train set (25:75)\n",
    "num_samples = 0.25 * len(XY_constant)\n",
    "row_ids = list(range(XY_constant.shape[0]))\n",
    "\n",
    "# randomly select 25% of the row ids\n",
    "selected_row_ids = random.sample(row_ids, round(num_samples))\n",
    "\n",
    "# subset to create train and test\n",
    "data_test = XY_constant.iloc[XY_constant.index.isin(selected_row_ids)]\n",
    "data_train = XY_constant.iloc[~XY_constant.index.isin(selected_row_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = data_train[\"Heart_Disease\"]\n",
    "Y_test = data_test[\"Heart_Disease\"]\n",
    "X_train = data_train.drop(columns=\"Heart_Disease\")\n",
    "X_test = data_test.drop(columns=\"Heart_Disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model\n",
    "\n",
    "<a id='running-model'></a>\n",
    "\n",
    "Now we can run a logistic regression model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "# transfrom predictions to binary\n",
    "prediction_binary = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy score\n",
    "accuracy = accuracy_score(y_true=Y_test, y_pred=prediction_binary)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating the coefficients <a id='simulating-coefficients'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the coefficients and their covariance matrix from the logistic regression fit\n",
    "beta_mean = model.params\n",
    "beta_cov = model.cov_params()\n",
    "# number of simulations\n",
    "n_simulations = 10000\n",
    "\n",
    "# simulate coefficients\n",
    "simulated_betas = multivariate_normal.rvs(\n",
    "    mean=beta_mean, cov=beta_cov, size=n_simulations\n",
    ")\n",
    "\n",
    "simulated_betas_odds = np.exp(simulated_betas)\n",
    "\n",
    "# derive probabilities from odds\n",
    "simulated_betas_p = simulated_betas_odds / (simulated_betas_odds + 1)\n",
    "\n",
    "# calculate mean p value per variable\n",
    "# Transpose the list of lists to group by variable (columns)\n",
    "variables = zip(*simulated_betas_p)  # Groups all simulations for each variable\n",
    "\n",
    "# Calculate mean p-values for each variable\n",
    "p_means = [sum(variable) / len(variable) for variable in variables]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean p values\n",
    "x_labels = data.columns.tolist()\n",
    "plt.bar(x_labels, p_means)\n",
    "plt.xticks(ticks = np.arange(1, 16, 1), labels = x_labels, rotation=45, ha='right', size = 7) \n",
    "plt.title('mean p value of logistic regression model per variable')\n",
    "plt.xlabel('variable')\n",
    "plt.ylabel('mean p value')\n",
    "plt.show()\n",
    "\n",
    "# boxplot of p values\n",
    "plt.boxplot(simulated_betas_odds, showfliers = False)\n",
    "plt.xticks(ticks = np.arange(1, 16, 1), labels = x_labels, rotation=45, ha='right', size = 7)  \n",
    "plt.axhline(y = 1, color = 'g')\n",
    "plt.axhline(y = 3, color = 'g')\n",
    "plt.title('odds of logistic regression model per variable')\n",
    "plt.xlabel('variable')\n",
    "plt.ylabel('p value')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of each coefficient to assess and interpret them\n",
    "for name, i in zip(X_test.columns, range(simulated_betas_odds.shape[1])):\n",
    "    plt.figure()\n",
    "    plt.hist(simulated_betas_odds[:, i], bins=30, color=\"skyblue\")\n",
    "    plt.axvline(\n",
    "        x=np.median(simulated_betas_odds, axis=0)[i],\n",
    "        color=\"orange\",\n",
    "        label=f\"Median {np.median(simulated_betas_odds, axis = 0)[i]:.2f}\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        x=np.percentile(simulated_betas_odds, 5, axis=0)[i],\n",
    "        color=\"orange\",\n",
    "        label=f\"5th Percentile {np.percentile(simulated_betas_odds, 5, axis = 0)[i]:.2f}\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        x=np.percentile(simulated_betas_odds, 95, axis=0)[i],\n",
    "        color=\"orange\",\n",
    "        label=f\"95th Percentile {np.percentile(simulated_betas_odds, 95, axis = 0)[i]:.2f}\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plt.title(f\"{name}\")\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Coefficients\n",
    "\n",
    "- The constant represents the baseline odds of having heart disease. This means that for a person with a poor or fair self perceived health status, who has not had a checkup in the past two years, who does not exercise, who does not have skin cancer or any other cancer, who does not have depression, who is not diabetic, who does not have arthritis, who is female, who is of average age, height, weight, and BMI, and who does not have a smoking history, the odds of having heart disease are 0.86 (0.83, 0.88). This indicates that the average person that falls into this category has a smaller chance of having heart disease than the chance of not having heart disease.\n",
    "\n",
    "- For individuals who _do_ exercise, the odds of having heart disease are 1.24 (1.21, 1.28) relative to those that do not. This means that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "<a id='pca'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original dataset has 19 variables, which would most likely be too much for a logistic regression model. We want to decrease this amount and ensure that the variables are not correlated in a way to make our model more accurate. To do this, we can use PCA. PCA finds 'principal components', which are the directions that explain maximal variance in the data in some direction. We can see it as a 'summary' of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding amount of components needed\n",
    "\n",
    "<a id='amount-components'></a>\n",
    "\n",
    "We want to retain 95% of the variance in the data, so we will use a trial-and error to find the amount of components we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=\"Heart_Disease\")\n",
    "\n",
    "# Percentage of variance that we want to keep, should be between 0 and 0.99\n",
    "percentage = 0.95\n",
    "components = 0\n",
    "\n",
    "# simulate a do-while loop\n",
    "while True:\n",
    "\n",
    "    pca = PCA(n_components=components)\n",
    "    pca_data = pca.fit_transform(X)\n",
    "\n",
    "    # if this is smaller than 0 we have kept at least percentage amount\n",
    "    # of variance in the PCA.\n",
    "    if percentage - sum(pca.explained_variance_ratio_) < 0:\n",
    "        break\n",
    "\n",
    "    components += 1\n",
    "\n",
    "print(\n",
    "    f\"Number of components to use to keep {percentage * 100:.0f}% of the variance: {components}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same procedure, but now in a plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of variance that we want to keep, should be between 0 and 0.99\n",
    "percentage = 0.95\n",
    "components = 0\n",
    "\n",
    "# simulate a do-while loop\n",
    "components = 0\n",
    "ys = []\n",
    "while True:\n",
    "\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit_transform(X)\n",
    "\n",
    "    # if this is smaller than 0 we have kept at least percentage amount\n",
    "    # of variance in the PCA.\n",
    "    ys.append(sum(pca.explained_variance_ratio_))\n",
    "    if percentage - sum(pca.explained_variance_ratio_) < 0:\n",
    "        break\n",
    "\n",
    "    components += 1\n",
    "\n",
    "print(\n",
    "    f\"Number of components to use to keep {percentage * 100:.0f}% of the variance: {components}\"\n",
    ")\n",
    "plt.scatter(range(len(ys)), ys, marker=\"x\", color=\"red\")\n",
    "plt.plot(range(len(ys)), ys, linestyle=\"--\")\n",
    "plt.xticks(range(len(ys)))\n",
    "plt.axhline(\n",
    "    percentage, color=\"green\", linestyle=\"dashdot\", label=\"Desired kept variance\"\n",
    ")\n",
    "plt.title(\n",
    "    f\"Number of components to use to keep {percentage * 100:.0f}% of the variance: {components}\"\n",
    ")\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Kept variance (%)\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{path}PCA_optimisation.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we know that we need 3 components to retain 95% of the variance in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pca.components_.T\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loading matrix tells us the weight each variable has in each component. This tell us the following:\n",
    "\n",
    "The first principal component is mostly explained by the BMI, weight and height of the person.\n",
    "\n",
    "The second principal component is mostly explained by the height and weight of the person.\n",
    "\n",
    "The third component is mostly explained by the age of the person.\n",
    "\n",
    "In conclusion we can say that the first and second component is mostly explained by the physical characteristics of a person, and the third component is explained by the age of the person.\n",
    "\n",
    "From literature we know that age is important, but the height of a person is not necessarily important for cardiovascular disease. This could be a sign that PCA loses some valuable information in the data. It could be better to hand-pick the important variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Cross-Validation (k-fold) for RQ_2:\n",
    "\n",
    "- $\\text{RQ}_2$: Does a logistic regression model based on PCA-generated components predict with higher accuracy than a logistic regression model fit on the 'clean' data?\n",
    "\n",
    "We had the following null hypothesis for this question:\n",
    "\n",
    "- $H_0$: A logistic regression model using PCA-generated components does not achieve significantly higher accuracy compared to a logistic regression model using the original 'clean' data.\n",
    "\n",
    "To test this hypothesis, and to find an answer to the research question, we performed k-fold cross validation on both models, and plotted the distribution of their respective accuracy scores, along with their respective means and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the target variable\n",
    "y = XY_constant[\"Heart_Disease\"]\n",
    "\n",
    "# define K for cross validation\n",
    "K = 500\n",
    "\n",
    "# setup the k-fold cross-validation\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# dictionary for the model names and features\n",
    "pca_df = pd.DataFrame(pca_data)\n",
    "# models = {'Base model': XY_constant.drop(columns='Heart_Disease'), 'PCA model': pca_df, 'Constant model': XY_constant['constant']}\n",
    "models = {\"Base model\": XY_constant.drop(columns=\"Heart_Disease\"), \"PCA model\": pca_df}\n",
    "\n",
    "# initialize a dictionary to store accuracy data and aic data\n",
    "acc_dict = {key: [] for key in models.keys()}\n",
    "aic_dict = {key: [] for key in models.keys()}\n",
    "\n",
    "for key, df in models.items():\n",
    "\n",
    "    for train_index, test_index in kf.split(XY_constant):\n",
    "\n",
    "        # Split into train and test according to the folds\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # For each fold split, fit the model\n",
    "        model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "\n",
    "        # convert probabilities to binary predictions\n",
    "        y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        acc_dict[key].append(accuracy_score(y_true=y_test, y_pred=y_pred_binary))\n",
    "        aic_dict[key].append(model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average aic of all models\n",
    "average_aic = {key: sum(aic) / len(aic) for key, aic in aic_dict.items()}\n",
    "\n",
    "colors = [\"palegreen\", \"paleturquoise\"]\n",
    "linecolors = [\"lightcoral\", \"goldenrod\"]\n",
    "\n",
    "# plot the histogram of the PCA accuracies and overlay the baseline model's mean\n",
    "for i, key in zip(range(len(acc_dict.keys())), acc_dict.keys()):\n",
    "    plt.hist(acc_dict[key], bins=25, color=colors[i], label=f\"{key} accuracies\")\n",
    "    plt.axvline(np.mean(acc_dict[key]), color=linecolors[i], linestyle=\"--\")\n",
    "    plt.axvline(np.percentile(acc_dict[key], 2.5), color=linecolors[i], linestyle=\":\")\n",
    "    plt.axvline(np.percentile(acc_dict[key], 97.5), color=linecolors[i], linestyle=\":\")\n",
    "\n",
    "# plt.hist(acc_dict['Constant model'], bins=30, color='firebrick', alpha=0.3, label='Constant model')\n",
    "plt.title(\"Distribution of k-fold computed accuracies\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{path}CrossVal_RQ2.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# print average aic scores\n",
    "print(\"average aic:\", average_aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the distribution of accuracy scores, we can quite clearly see that a logistic regression model using PCA-generated components does not achieve significantly higher accuracy compared to a logistic regression model using the original 'clean' data. As such, we _fail to reject_ our null hypothesis. The answer to our research question becomes:\n",
    "  - No, a logistic regression model based on PCA-generated components does not predict with higher accuracy than a logistic regression model fit on the ‘clean’ data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is not all we can interpret from these distributions:\n",
    "\n",
    "- We can see that the model fit on all variables centres around a very high accuracy score of _roughly_ 78%. Since we trained the model on all variables, this accuracy could very much be the result of overfitting.\n",
    "- As such, we should run another cross validation, this time for each possible combination of variables in the given data.\n",
    "  - This way, we can find out which combinations of variables yield the best results.\n",
    "    - Finding smaller sets of variables that yield good results can be considered better, as they are less likely to overfit.\n",
    "  - We can also learn more about which variables are the most predictive.\n",
    "- We constructed the following research question to guide this process:\n",
    "\n",
    "  - $RQ_3$: Can we extract how many variables - and which - contribute to a high model accuracy?\n",
    "\n",
    "- However, such an approach requires extensive computational power, and was unfortunately not feasible given the project timeline.\n",
    "- Instead, we selected five variables based on literature, which have been found to be key indicators of heart disease:\n",
    "  - Age\n",
    "  - Gender\n",
    "  - Smoking\n",
    "  - Exercise\n",
    "  - Diabetes\n",
    "- We then performed cross validation on five different models, adding one variable - in the same order as listed above - each model.\n",
    "- The results are listed below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing K-fold for select variables and plotting the distribution of their accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define K for cross validation\n",
    "K = 100\n",
    "\n",
    "# setup the k-fold cross-validation\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# dictionary for the model names and features\n",
    "models = {\n",
    "    \"Age\": XY_constant[[\"constant\", \"Age_Normalised\"]],\n",
    "    \"Age+Gender\": XY_constant[[\"constant\", \"Age_Normalised\", \"Sex_Male\"]],\n",
    "    \"Age+Gender+Smoking\": XY_constant[\n",
    "        [\"constant\", \"Age_Normalised\", \"Sex_Male\", \"Smoking_History\"]\n",
    "    ],\n",
    "    \"Age+Gender+Smoking+Exercise\": XY_constant[\n",
    "        [\"constant\", \"Age_Normalised\", \"Sex_Male\", \"Smoking_History\", \"Exercise\"]\n",
    "    ],\n",
    "    \"Age+Gender+Smoking+Exercise+Diabetic\": XY_constant[\n",
    "        [\n",
    "            \"constant\",\n",
    "            \"Age_Normalised\",\n",
    "            \"Sex_Male\",\n",
    "            \"Smoking_History\",\n",
    "            \"Exercise\",\n",
    "            \"Diabetic\",\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "# initialize a dictionary to store accuracy data and aic data\n",
    "acc_dict = {key: [] for key in models.keys()}\n",
    "aic_dict = {key: [] for key in models.keys()}\n",
    "\n",
    "for key, df in models.items():\n",
    "\n",
    "    for train_index, test_index in kf.split(XY_constant):\n",
    "\n",
    "        # Split into train and test according to the folds\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # For each fold split, fit the model\n",
    "        model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "\n",
    "        # convert probabilities to binary predictions\n",
    "        y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        acc_dict[key].append(accuracy_score(y_true=y_test, y_pred=y_pred_binary))\n",
    "        aic_dict[key].append(model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our data into an array like structure or DataFrame\n",
    "accuracies_for_box = pd.DataFrame(acc_dict)\n",
    "\n",
    "plt.boxplot(accuracies_for_box, showfliers=False)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks([1, 2, 3, 4, 5], labels=accuracies_for_box.columns, rotation=45)\n",
    "for i in range(len(accuracies_for_box.columns)):\n",
    "    plt.axvline(i + 1, color=\"grey\", alpha=0.3, linestyle=\"--\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Boxplot of accuracy scores for models with select variables\")\n",
    "plt.savefig(f\"{path}Select_Variable_CrossVal_A.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the resulting accuracy distributions for each model in a boxplot, as can be seen above. We observe the following:\n",
    "\n",
    "- Age alone yields accuracies around 50-55%, which can be considered relatively low compared to what we've seen before.\n",
    "- Through the addition of variables, the accuracy gradually increases.\n",
    "- The model fit on the variables `age`, `gender`, `smoking`, and `exercise` yields the highest overall accuracy, getting close to 80%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this alone does not tell us enough. As we said before, in an ideal situation we would test each possible combination of variables. The next best thing we can do now, is perform this same analysis, but with the variables reversed. Then, we could determine whether the climbing accuracy occurs due to the addition of more variables, or if it occurs due to the specific variables which are added.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing K-fold for reversed selection of variables and plotting the distribution of their accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define K for cross validation\n",
    "K = 100\n",
    "\n",
    "# setup the k-fold cross-validation\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# dictionary for the model names and features\n",
    "models = {\n",
    "    \"Diabetic\": XY_constant[[\"constant\", \"Diabetic\"]],\n",
    "    \"Diabetic+Exercise\": XY_constant[[\"constant\", \"Diabetic\", \"Exercise\"]],\n",
    "    \"Diabetic+Exercise+Smoking\": XY_constant[\n",
    "        [\"constant\", \"Diabetic\", \"Exercise\", \"Smoking_History\"]\n",
    "    ],\n",
    "    \"Diabetic+Exercise+Smoking+Gender\": XY_constant[\n",
    "        [\"constant\", \"Diabetic\", \"Exercise\", \"Smoking_History\", \"Sex_Male\"]\n",
    "    ],\n",
    "    \"Diabetic+Exercise+Smoking+Gender+Age\": XY_constant[\n",
    "        [\n",
    "            \"constant\",\n",
    "            \"Diabetic\",\n",
    "            \"Exercise\",\n",
    "            \"Smoking_History\",\n",
    "            \"Sex_Male\",\n",
    "            \"Age_Normalised\",\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "# initialize a dictionary to store accuracy data and aic data\n",
    "acc_dict = {key: [] for key in models.keys()}\n",
    "aic_dict = {key: [] for key in models.keys()}\n",
    "\n",
    "for key, df in models.items():\n",
    "\n",
    "    for train_index, test_index in kf.split(XY_constant):\n",
    "\n",
    "        # Split into train and test according to the folds\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # For each fold split, fit the model\n",
    "        model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "\n",
    "        # convert probabilities to binary predictions\n",
    "        y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        acc_dict[key].append(accuracy_score(y_true=y_test, y_pred=y_pred_binary))\n",
    "        aic_dict[key].append(model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our data into an array like structure or DataFrame\n",
    "accuracies_for_box = pd.DataFrame(acc_dict)\n",
    "\n",
    "plt.boxplot(accuracies_for_box, showfliers=False)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(\n",
    "    [i + 1 for i in range(len(accuracies_for_box.columns))],\n",
    "    labels=accuracies_for_box.columns,\n",
    "    rotation=45,\n",
    ")\n",
    "for i in range(len(accuracies_for_box.columns)):\n",
    "    plt.axvline(i + 1, color=\"grey\", alpha=0.3, linestyle=\"--\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Boxplot of accuracy scores for models with select variables\")\n",
    "plt.savefig(f\"{path}Select_Variable_CrossVal_B.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the results for the reversed order, we can spot some interesting things.\n",
    "\n",
    "- `Diabetes` does not appear to be a strong predictor, despite its frequent academic mentioning as one.\n",
    "- Despite `diabetes` not being a strong predictor, when paired with `exercise`, the model accuracy jumps to roughly 70-something percent.\n",
    "- As more variables are added, the accuracy does not change by much.\n",
    "- This indicates that `exercise` may be the variable that is doing the heavy lifting in terms of predictability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following these results, we perform one final cross validation. This time, only using the `exercise` variable. The results can be seen below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define K for cross validation\n",
    "K = 200\n",
    "\n",
    "# setup the k-fold cross-validation\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# dictionary for the model names and features\n",
    "models = {\n",
    "    \"Exercise\": XY_constant[[\"constant\", \"Exercise\"]],\n",
    "}\n",
    "\n",
    "# initialize a dictionary to store accuracy data and aic data\n",
    "acc_dict = {key: [] for key in models.keys()}\n",
    "aic_dict = {key: [] for key in models.keys()}\n",
    "\n",
    "for key, df in models.items():\n",
    "\n",
    "    for train_index, test_index in kf.split(XY_constant):\n",
    "\n",
    "        # Split into train and test according to the folds\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # For each fold split, fit the model\n",
    "        model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "\n",
    "        # convert probabilities to binary predictions\n",
    "        y_pred_binary = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        acc_dict[key].append(accuracy_score(y_true=y_test, y_pred=y_pred_binary))\n",
    "        aic_dict[key].append(model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our data into an array like structure or DataFrame\n",
    "accuracies_for_box = pd.DataFrame(acc_dict)\n",
    "\n",
    "plt.boxplot(accuracies_for_box, showfliers=False)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks([1], labels=accuracies_for_box.columns, rotation=45)\n",
    "plt.axvline(1, color=\"grey\", alpha=0.3, linestyle=\"--\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Boxplot of accuracy scores for models with select variables\")\n",
    "plt.savefig(f\"{path}Exercise_CrossVal.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that if we build a model using only an intercept and the `exercise` feature, we yield an accuracy score of roughly 70%. This tells us that `exercise` is a very predictive feature - as we suspected earlier. However, we must be weary of how we interpret this. Firstly, as a standalone analysis, this does not tell us anything about the direction of the relationship between exercise and heart disease. Luckily, we looked into this earlier. We also need to consider the fact that there may be some autocorrelation or codependence which causes exercise to be so predictable.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
